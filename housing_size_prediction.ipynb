{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eb337df-0323-4805-a693-13fb6d1ce6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "082f81ec-6ab6-4ff6-a842-660982358fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brokered_by</th>\n",
       "      <th>status</th>\n",
       "      <th>price</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>acre_lot</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>house_size</th>\n",
       "      <th>prev_sold_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103378.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1962661.0</td>\n",
       "      <td>Adjuntas</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>601.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52707.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1902874.0</td>\n",
       "      <td>Adjuntas</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>601.0</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103379.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1404990.0</td>\n",
       "      <td>Juana Diaz</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>795.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31239.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1947675.0</td>\n",
       "      <td>Ponce</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>731.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34632.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>331151.0</td>\n",
       "      <td>Mayaguez</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>680.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>103378.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>179000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1850806.0</td>\n",
       "      <td>San Sebastian</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>612.0</td>\n",
       "      <td>2520.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1205.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1298094.0</td>\n",
       "      <td>Ciales</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>639.0</td>\n",
       "      <td>2040.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50739.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>71600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1048466.0</td>\n",
       "      <td>Ponce</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>731.0</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>81909.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>734904.0</td>\n",
       "      <td>Ponce</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>730.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>65672.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.46</td>\n",
       "      <td>1946226.0</td>\n",
       "      <td>Las Marias</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>670.0</td>\n",
       "      <td>5403.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>52707.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>89000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.39</td>\n",
       "      <td>1902814.0</td>\n",
       "      <td>Isabela</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>662.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>52707.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1773902.0</td>\n",
       "      <td>Juana Diaz</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>795.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>46019.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1946165.0</td>\n",
       "      <td>Lares</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>669.0</td>\n",
       "      <td>4161.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>52707.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1761024.0</td>\n",
       "      <td>Utuado</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>641.0</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>88441.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>649000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1879215.0</td>\n",
       "      <td>Ponce</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>731.0</td>\n",
       "      <td>2677.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    brokered_by    status     price  bed  bath  acre_lot     street  \\\n",
       "0      103378.0  for_sale  105000.0  3.0   2.0      0.12  1962661.0   \n",
       "1       52707.0  for_sale   80000.0  4.0   2.0      0.08  1902874.0   \n",
       "2      103379.0  for_sale   67000.0  2.0   1.0      0.15  1404990.0   \n",
       "3       31239.0  for_sale  145000.0  4.0   2.0      0.10  1947675.0   \n",
       "4       34632.0  for_sale   65000.0  6.0   2.0      0.05   331151.0   \n",
       "5      103378.0  for_sale  179000.0  4.0   3.0      0.46  1850806.0   \n",
       "6        1205.0  for_sale   50000.0  3.0   1.0      0.20  1298094.0   \n",
       "7       50739.0  for_sale   71600.0  3.0   2.0      0.08  1048466.0   \n",
       "8       81909.0  for_sale  100000.0  2.0   1.0      0.09   734904.0   \n",
       "9       65672.0  for_sale  300000.0  5.0   3.0      7.46  1946226.0   \n",
       "10      52707.0  for_sale   89000.0  3.0   2.0     13.39  1902814.0   \n",
       "11      52707.0  for_sale  150000.0  3.0   2.0      0.08  1773902.0   \n",
       "12      46019.0  for_sale  155000.0  3.0   2.0      0.10  1946165.0   \n",
       "13      52707.0  for_sale   79000.0  5.0   2.0      0.12  1761024.0   \n",
       "14      88441.0  for_sale  649000.0  5.0   5.0      0.74  1879215.0   \n",
       "\n",
       "             city        state  zip_code  house_size prev_sold_date  \n",
       "0        Adjuntas  Puerto Rico     601.0       920.0            NaN  \n",
       "1        Adjuntas  Puerto Rico     601.0      1527.0            NaN  \n",
       "2      Juana Diaz  Puerto Rico     795.0       748.0            NaN  \n",
       "3           Ponce  Puerto Rico     731.0      1800.0            NaN  \n",
       "4        Mayaguez  Puerto Rico     680.0         NaN            NaN  \n",
       "5   San Sebastian  Puerto Rico     612.0      2520.0            NaN  \n",
       "6          Ciales  Puerto Rico     639.0      2040.0            NaN  \n",
       "7           Ponce  Puerto Rico     731.0      1050.0            NaN  \n",
       "8           Ponce  Puerto Rico     730.0      1092.0            NaN  \n",
       "9      Las Marias  Puerto Rico     670.0      5403.0            NaN  \n",
       "10        Isabela  Puerto Rico     662.0      1106.0            NaN  \n",
       "11     Juana Diaz  Puerto Rico     795.0      1045.0            NaN  \n",
       "12          Lares  Puerto Rico     669.0      4161.0            NaN  \n",
       "13         Utuado  Puerto Rico     641.0      1620.0            NaN  \n",
       "14          Ponce  Puerto Rico     731.0      2677.0            NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = pd.read_csv('genhousedata.csv'\n",
    "                  )\n",
    "df = file\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbec6ace-ae4f-40b5-aebe-24c0e5b2710a",
   "metadata": {},
   "source": [
    "# This is the original CSV. As you can see the fifth house among 568483 others are missing it's house size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90b410c7-d6e7-4d85-9614-447f850091d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brokered_by         4533\n",
       "status                 0\n",
       "price               1541\n",
       "bed               481317\n",
       "bath              511771\n",
       "acre_lot          325589\n",
       "street             10866\n",
       "city                1407\n",
       "state                  8\n",
       "zip_code             299\n",
       "house_size        568484\n",
       "prev_sold_date    734297\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4eb347-59d2-4d50-97e9-4e4c145c698f",
   "metadata": {},
   "source": [
    "# Above are the missing values for all columns in this data set. Below the model begins. In the next cell the MAE, RMSE, and R2 scores are shown for model accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dd572af-dc2c-4693-a615-4d92aedb8eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025541 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 40618\n",
      "[LightGBM] [Info] Number of data points in the train set: 1294270, number of used features: 20038\n",
      "[LightGBM] [Info] Start training from score 1905.541743\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"genhousedata.csv\")\n",
    "\n",
    "features = ['price', 'bed', 'bath', 'acre_lot', 'city', 'state', 'zip_code', 'status']\n",
    "target = 'house_size'\n",
    "\n",
    "# Split data into with and without house_size\n",
    "df_with_size = df[df[target].notnull()]\n",
    "df_missing_size = df[df[target].isnull()]\n",
    "\n",
    "# Drop rows with missing features in training data\n",
    "train_data = df_with_size[features + [target]].dropna(subset=features)\n",
    "\n",
    "# Calculate IQR to define outliers\n",
    "Q1 = train_data[target].quantile(0.25)\n",
    "Q3 = train_data[target].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower = Q1 - 1.5 * IQR\n",
    "upper = Q3 + 1.5 * IQR\n",
    "\n",
    "# Add outlier/normal flag column to the entire dataset (NaN for missing house_size)\n",
    "def label_outlier(row):\n",
    "    val = row[target]\n",
    "    if pd.isna(val):\n",
    "        return np.nan\n",
    "    return 'outlier' if (val < lower or val > upper) else 'normal'\n",
    "\n",
    "df['size_label'] = df.apply(label_outlier, axis=1)\n",
    "\n",
    "# Preprocessing setup\n",
    "numeric_features = ['price', 'bed', 'bath', 'acre_lot']\n",
    "categorical_features = ['city', 'state', 'zip_code', 'status']\n",
    "\n",
    "numeric_transformer = SimpleImputer(strategy='median')\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=True))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# Fit preprocessor on training data features\n",
    "X_train = train_data[features]\n",
    "y_train = train_data[target]\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "# Train only the normal model on the whole training set (including outliers if you want, but recommended just normal)\n",
    "normal_train_data = train_data[(train_data[target] >= lower) & (train_data[target] <= upper)]\n",
    "Xn_train = normal_train_data[features]\n",
    "yn_train = normal_train_data[target]\n",
    "\n",
    "normal_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LGBMRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "normal_model.fit(Xn_train, yn_train)\n",
    "\n",
    "# Predict missing house_size values using normal_model only\n",
    "X_missing = df_missing_size[features].copy()\n",
    "preds = normal_model.predict(X_missing)\n",
    "\n",
    "# Fill in missing house_size with predictions\n",
    "df.loc[X_missing.index, target] = preds\n",
    "\n",
    "# Optionally, update size_label for these newly predicted rows\n",
    "def label_predicted_size(size):\n",
    "    return 'normal' if (lower <= size <= upper) else 'outlier'\n",
    "\n",
    "df.loc[X_missing.index, 'size_label'] = [label_predicted_size(s) for s in preds]\n",
    "\n",
    "# Now df has missing house_size filled and a new column 'size_label' indicating normal/outlier\n",
    "\n",
    "# You can save the updated dataframe if you want\n",
    "#df.to_csv(\"genhousedata_filled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3910bf6-a229-4ad3-8cb2-6c598b3e734e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 40618\n",
      "[LightGBM] [Info] Number of data points in the train set: 1035416, number of used features: 20041\n",
      "[LightGBM] [Info] Start training from score 1905.852493\n",
      "📊 Normal Model Evaluation on Validation Set:\n",
      "   MAE:  291.81 sq ft\n",
      "   RMSE: 391.84 sq ft\n",
      "   R²:   0.7293\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# === Add after fitting the model ===\n",
    "\n",
    "# Create validation split from normal data\n",
    "Xn_train_split, Xn_valid_split, yn_train_split, yn_valid_split = train_test_split(\n",
    "    Xn_train, yn_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train model on split training set\n",
    "normal_model_split = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LGBMRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "normal_model_split.fit(Xn_train_split, yn_train_split)\n",
    "\n",
    "# Predict on validation set\n",
    "preds_valid = normal_model_split.predict(Xn_valid_split)\n",
    "\n",
    "# Evaluate\n",
    "mae = mean_absolute_error(yn_valid_split, preds_valid)\n",
    "rmse = np.sqrt(mean_squared_error(yn_valid_split, preds_valid))\n",
    "r2 = r2_score(yn_valid_split, preds_valid)\n",
    "\n",
    "print(\"📊 Normal Model Evaluation on Validation Set:\")\n",
    "print(f\"   MAE:  {mae:.2f} sq ft\")\n",
    "print(f\"   RMSE: {rmse:.2f} sq ft\")\n",
    "print(f\"   R²:   {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4db3da-824b-40ed-9709-5de95fe68853",
   "metadata": {},
   "source": [
    "# These accuracy metrics indicate that the predictions may vary by approximately ±300 square feet, which is roughly the size of a one person small private office. This level of error is acceptable for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "185d3e41-9d08-4c88-88c9-3833fa4943aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brokered_by         4533\n",
       "status                 0\n",
       "price               1541\n",
       "bed               481317\n",
       "bath              511771\n",
       "acre_lot          325589\n",
       "street             10866\n",
       "city                1407\n",
       "state                  8\n",
       "zip_code             299\n",
       "house_size             0\n",
       "prev_sold_date    734297\n",
       "size_label             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b7f073-7b68-41b2-9f17-b5ce11a0b8f9",
   "metadata": {},
   "source": [
    "# Missing house sizes here have gone from 568484 to 0. All missing values were filled by the predictor!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcc49db2-befe-45b5-9cc7-876ddf9c8608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round predicted house_size values to, say, 2 decimal places (change as needed)\n",
    "df.loc[X_missing.index, target] = preds.round(0)  # Keep as float, just rounded\n",
    "\n",
    "# Update size_label for predicted rows based on the rounded predictions\n",
    "df.loc[X_missing.index, 'size_label'] = [label_predicted_size(s) for s in df.loc[X_missing.index, target]]\n",
    "\n",
    "# Add a new column to flag predicted vs original\n",
    "df['house_size_predicted'] = False  # Default: False for all original values\n",
    "df.loc[X_missing.index, 'house_size_predicted'] = True  # Mark predicted rows as True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33832cf0-3ea5-4808-a1fa-80cd0439fbf4",
   "metadata": {},
   "source": [
    "# The code above rounds the predicted house size values to the nearest whole number and creates a new column indicating whether each house size was predicted or originally present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba33eb79-e1b5-424d-a13f-7d7083836881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"genhousedata_filled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca2c9dbd-a66a-43c7-9c5a-d82e4951bbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1584831 original rows with normal house sizes.\n",
      "568484 predicted rows with normal house sizes.\n",
      "73067 original rows with outlier house sizes.\n",
      "0 predicted rows with an outlier house size.\n",
      "2226382 total rows.\n"
     ]
    }
   ],
   "source": [
    "norm_rows = df[(df['size_label'] == 'normal') & (df['house_size_predicted'] == True)]\n",
    "norm_rows1 = df[(df['size_label'] == 'normal') & (df['house_size_predicted'] == False)]\n",
    "norm_rows2 = df[(df['size_label'] == 'outlier') & (df['house_size_predicted'] == True)]\n",
    "norm_rows3 = df[(df['size_label'] == 'outlier') & (df['house_size_predicted'] == False)]\n",
    "\n",
    "print (f\"{len(norm_rows1)} original rows with normal house sizes.\")\n",
    "print (f\"{len(norm_rows)} predicted rows with normal house sizes.\")\n",
    "print (f\"{len(norm_rows3)} original rows with outlier house sizes.\")\n",
    "print (f\"{len(norm_rows2)} predicted rows with an outlier house size.\")\n",
    "print (f\"{len(df)} total rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1966d146-38e8-469e-8776-bc2e52477c06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
